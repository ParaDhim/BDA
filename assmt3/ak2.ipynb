{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "CypherSyntaxError",
     "evalue": "{code: Neo.ClientError.Statement.SyntaxError} {message: A pattern expression should only be used in order to test the existence of a pattern. It should therefore only be used in contexts that evaluate to a boolean, e.g. inside the function exists() or in a WHERE-clause. No other uses are allowed, instead they should be replaced by a pattern comprehension. (line 1, column 42 (offset: 41))\n\"MATCH (p:Paper) RETURN p.id AS id, COUNT((p)-[:CITES]->()) AS in_degree, COUNT(()-[:CITES]->(p)) AS out_degree\"\n                                          ^}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCypherSyntaxError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/1752256639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Corrected Cypher query to fetch in-degree and out-degree for each paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MATCH (p:Paper) RETURN p.id AS id, COUNT((p)-[:CITES]->()) AS in_degree, COUNT(()-[:CITES]->(p)) AS out_degree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_degree\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_degree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out_degree\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mbookmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bookmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         self._auto_result._run(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exhausted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         )\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midle_since\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_bolt5.py\u001b[0m in \u001b[0;36m_process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server_state_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbolt_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatabaseUnavailable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mon_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hydrate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_ignored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCypherSyntaxError\u001b[0m: {code: Neo.ClientError.Statement.SyntaxError} {message: A pattern expression should only be used in order to test the existence of a pattern. It should therefore only be used in contexts that evaluate to a boolean, e.g. inside the function exists() or in a WHERE-clause. No other uses are allowed, instead they should be replaced by a pattern comprehension. (line 1, column 42 (offset: 41))\n\"MATCH (p:Paper) RETURN p.id AS id, COUNT((p)-[:CITES]->()) AS in_degree, COUNT(()-[:CITES]->(p)) AS out_degree\"\n                                          ^}"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, array_contains\n",
    "import networkx as nx\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from math import sqrt\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"paras2003\"))\n",
    "\n",
    "# # Create citation graph in Neo4j\n",
    "# with driver.session() as session:\n",
    "#     for row in data:\n",
    "#         paper_id = row['paper']\n",
    "#         references = row['reference']\n",
    "        \n",
    "#         # Create paper node\n",
    "#         session.run(\"CREATE (p:Paper {id: $paper_id})\", paper_id=paper_id)\n",
    "        \n",
    "#         # Create citation relationships\n",
    "#         for ref in references:\n",
    "#             session.run(\"MATCH (p1:Paper {id: $paper_id}) \"\n",
    "#                        \"MATCH (p2:Paper {id: $ref}) \"\n",
    "#                        \"CREATE (p1)-[:CITES]->(p2)\", paper_id=paper_id, ref=ref)\n",
    "\n",
    "# Load citation graph into NetworkX\n",
    "G = nx.DiGraph()\n",
    "# with driver.session() as session:\n",
    "#     result = session.run(\"MATCH (p:Paper) RETURN p.id AS id, size([(p)-[:CITES]->() | 1]) AS in_degree, size([(()-[:CITES]->(p) | 1]) AS out_degree\")\n",
    "#     for record in result:\n",
    "#         G.add_node(record[\"id\"], in_degree=record[\"in_degree\"], out_degree=record[\"out_degree\"])\n",
    "#     result = session.run(\"MATCH (p1:Paper)-[r:CITES]->(p2:Paper) RETURN p1.id, p2.id\")\n",
    "#     for record in result:\n",
    "#         G.add_edge(record[\"p1.id\"], record[\"p2.id\"])\n",
    "# Corrected Cypher query to fetch in-degree and out-degree for each paper\n",
    "# Corrected Cypher query to fetch in-degree and out-degree for each paper\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"MATCH (p:Paper) RETURN p.id AS id, COUNT((p)-[:CITES]->()) AS in_degree, COUNT(()-[:CITES]->(p)) AS out_degree\")\n",
    "    for record in result:\n",
    "        G.add_node(record[\"id\"], in_degree=record[\"in_degree\"], out_degree=record[\"out_degree\"])\n",
    "\n",
    "    result = session.run(\"MATCH (p1:Paper)-[r:CITES]->(p2:Paper) RETURN p1.id, p2.id\")\n",
    "    for record in result:\n",
    "        G.add_edge(record[\"p1.id\"], record[\"p2.id\"])\n",
    "\n",
    "# Now proceed with the SimRank computation as before.\n",
    "\n",
    "\n",
    "# Now proceed with the SimRank computation as before.\n",
    "\n",
    "\n",
    "# Run SimRank algorithm on the citation graph\n",
    "spark = SparkSession.builder.appName(\"SimRank\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "@udf(DoubleType())\n",
    "def simrank_score(src_id, dst_id):\n",
    "    \"\"\"\n",
    "    Calculate the SimRank score between two nodes.\n",
    "    \n",
    "    Parameters:\n",
    "    src_id (str): Source node ID\n",
    "    dst_id (str): Destination node ID\n",
    "    \n",
    "    Returns:\n",
    "    float: SimRank score between the source and destination nodes\n",
    "    \"\"\"\n",
    "    if src_id == dst_id:\n",
    "        return 1.0\n",
    "    \n",
    "    src_neighbors = [n for n in G.neighbors(src_id)]\n",
    "    dst_neighbors = [n for n in G.neighbors(dst_id)]\n",
    "    \n",
    "    if not src_neighbors or not dst_neighbors:\n",
    "        return 0.0\n",
    "    \n",
    "    score = 0.0\n",
    "    for src_neighbor in src_neighbors:\n",
    "        for dst_neighbor in dst_neighbors:\n",
    "            score += simrank_score(src_neighbor, dst_neighbor)\n",
    "    \n",
    "    return importance_factor * score / (len(src_neighbors) * len(dst_neighbors))\n",
    "\n",
    "def simrank(G, source, importance_factor, max_iterations, tolerance):\n",
    "    \"\"\"\n",
    "    Run the SimRank algorithm on the citation graph.\n",
    "    \n",
    "    Parameters:\n",
    "    G (networkx.DiGraph): Citation graph\n",
    "    source (list): List of source node IDs to compute similarity for\n",
    "    importance_factor (float): SimRank importance factor\n",
    "    max_iterations (int): Maximum number of iterations\n",
    "    tolerance (float): Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "    list: List of SimRank scores for the source nodes\n",
    "    \"\"\"\n",
    "    # Convert NetworkX graph to Spark DataFrame\n",
    "    nodes = [(n, d[\"in_degree\"], d[\"out_degree\"]) for n, d in G.nodes(data=True)]\n",
    "    edges = [(u, v) for u, v in G.edges()]\n",
    "    node_schema = StructType([\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"in_degree\", IntegerType(), True),\n",
    "        StructField(\"out_degree\", IntegerType(), True)\n",
    "    ])\n",
    "    edge_schema = StructType([\n",
    "        StructField(\"src\", StringType(), True),\n",
    "        StructField(\"dst\", StringType(), True)\n",
    "    ])\n",
    "    node_df = spark.createDataFrame(nodes, schema=node_schema)\n",
    "    edge_df = spark.createDataFrame(edges, schema=edge_schema)\n",
    "    \n",
    "    # Compute SimRank scores\n",
    "    sim_scores = node_df.crossJoin(node_df.alias(\"other\"))\n",
    "    sim_scores = sim_scores.withColumn(\"similarity\", simrank_score(col(\"id\"), col(\"other.id\")))\n",
    "    sim_scores = sim_scores.filter(array_contains(source, col(\"id\")) | array_contains(source, col(\"other.id\")))\n",
    "    return sim_scores.collect()\n",
    "\n",
    "# Run SimRank with different importance factors\n",
    "source_nodes = [2982615777, 1556418098]\n",
    "for importance_factor in [0.7, 0.8, 0.9]:\n",
    "    print(f\"SimRank with importance factor: {importance_factor}\")\n",
    "    sim_scores = simrank(G, source_nodes, importance_factor, 1000, 0.0001)\n",
    "    for row in sim_scores:\n",
    "        print(f\"Similarity between {row['id']} and {row['other.id']}: {row['similarity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neo4j graph...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/159026447.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;31m# Create Neo4j graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating Neo4j graph...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_neo4j_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;31m# Run analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/159026447.py\u001b[0m in \u001b[0;36mcreate_neo4j_graph\u001b[0;34m(self, papers_data)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Create paper nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpaper_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 session.run(\"\"\"\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mCREATE\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPaper\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m$\u001b[0m\u001b[0mpaper_id\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \"\"\", paper_id=paper_id)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;31m# This will buffer upp all records for the previous auto-commit tx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_buffer_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_buffer_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_obtain_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResultSummary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_buffer\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mrecord_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mrecord_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_streaming\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_discarding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_discard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;31m# Receive exactly one message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m         tag, fields = self.inbox.pop(\n\u001b[0m\u001b[1;32m    992\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, hydration_hooks)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_one_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unpacker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_structure_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36m_buffer_one_chunk\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;31m# Determine the chunk size and skip noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                     \u001b[0mreceive_into_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m                     \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop_u16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mchunk_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mreceive_into_buffer\u001b[0;34m(sock, buffer, n_bytes)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             n = sock.recv_into(\n\u001b[0m\u001b[1;32m    346\u001b[0m                 \u001b[0mview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_async_compat/network/_bolt_socket.py\u001b[0m in \u001b[0;36m_wait_for_io\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_io\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mdeadline_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "class CitationGraphAnalyzer:\n",
    "    def __init__(self, neo4j_uri=\"bolt://localhost:7687\", \n",
    "                 neo4j_user=\"neo4j\", neo4j_password=\"paras2003\"):\n",
    "        \"\"\"Initialize with Neo4j and Spark connections\"\"\"\n",
    "        # Initialize Neo4j connection\n",
    "        self.driver = GraphDatabase.driver(neo4j_uri, \n",
    "                                         auth=(neo4j_user, neo4j_password))\n",
    "        \n",
    "        # Initialize Spark session\n",
    "        self.spark = SparkSession.builder \\\n",
    "            .appName(\"Citation Graph Analysis\") \\\n",
    "            .config(\"spark.driver.memory\", \"4g\") \\\n",
    "            .config(\"spark.executor.memory\", \"4g\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    def create_neo4j_graph(self, papers_data):\n",
    "        \"\"\"Create graph in Neo4j from citation data\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Clear existing data\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "            \n",
    "            # Create paper nodes\n",
    "            for paper_id in papers_data.keys():\n",
    "                session.run(\"\"\"\n",
    "                    CREATE (p:Paper {id: $paper_id})\n",
    "                \"\"\", paper_id=paper_id)\n",
    "            \n",
    "            # Create citation relationships\n",
    "            for citing_paper, cited_papers in papers_data.items():\n",
    "                if cited_papers:  # Only create edges if there are references\n",
    "                    for cited_paper in cited_papers:\n",
    "                        session.run(\"\"\"\n",
    "                            MATCH (citing:Paper {id: $citing_id})\n",
    "                            MATCH (cited:Paper {id: $cited_id})\n",
    "                            CREATE (citing)-[:CITES]->(cited)\n",
    "                        \"\"\", citing_id=citing_paper, cited_id=cited_paper)\n",
    "                        \n",
    "    def get_graph_data(self):\n",
    "        \"\"\"Extract graph data from Neo4j for Spark processing\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # Get all citation relationships\n",
    "            result = session.run(\"\"\"\n",
    "                MATCH (p1:Paper)-[:CITES]->(p2:Paper)\n",
    "                RETURN p1.id as source, p2.id as target\n",
    "            \"\"\")\n",
    "            edges = [(record[\"source\"], record[\"target\"]) for record in result]\n",
    "            \n",
    "            return edges\n",
    "    \n",
    "    from pyspark.sql import functions as F\n",
    "\n",
    "    def compute_simrank_similarity(self, query_node, target_node, in_neighbors_dict, C=0.9, max_iterations=10, tolerance=1e-4):\n",
    "        \"\"\"Calculate SimRank similarity between query and target nodes using Spark and Neo4j data\"\"\"\n",
    "        if query_node == target_node:\n",
    "            return 1.0  # self-similarity is always 1.0\n",
    "\n",
    "        in_neighbors_a = in_neighbors_dict.get(query_node, [])\n",
    "        in_neighbors_b = in_neighbors_dict.get(target_node, [])\n",
    "        \n",
    "        if not in_neighbors_a or not in_neighbors_b:\n",
    "            return 0.0\n",
    "        \n",
    "        # Initial similarity score\n",
    "        sim_scores = defaultdict(lambda: defaultdict(float))\n",
    "        for node in set(in_neighbors_a + in_neighbors_b):\n",
    "            sim_scores[node][node] = 1.0\n",
    "\n",
    "        # Perform SimRank iterations\n",
    "        for _ in range(max_iterations):\n",
    "            new_scores = defaultdict(lambda: defaultdict(float))\n",
    "            max_diff = 0.0\n",
    "            \n",
    "            # Compute similarity between in-neighbors\n",
    "            for a_in in in_neighbors_a:\n",
    "                for b_in in in_neighbors_b:\n",
    "                    if a_in == b_in:\n",
    "                        new_scores[a_in][b_in] = 1.0\n",
    "                        continue\n",
    "                    \n",
    "                    in_a_in = in_neighbors_dict.get(a_in, [])\n",
    "                    in_b_in = in_neighbors_dict.get(b_in, [])\n",
    "                    \n",
    "                    if not in_a_in or not in_b_in:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate new similarity score based on neighbors\n",
    "                    similarity_sum = sum(sim_scores[i][j] for i, j in product(in_a_in, in_b_in))\n",
    "                    new_sim = (C / (len(in_a_in) * len(b_in))) * similarity_sum\n",
    "                    new_scores[a_in][b_in] = new_sim\n",
    "                    new_scores[b_in][a_in] = new_sim\n",
    "                    \n",
    "                    # Track the maximum change for convergence\n",
    "                    max_diff = max(max_diff, abs(new_sim - sim_scores[a_in][b_in]))\n",
    "            \n",
    "            # Update scores\n",
    "            sim_scores = new_scores\n",
    "            if max_diff < tolerance:\n",
    "                break\n",
    "\n",
    "        # Final similarity between query_node and target_node\n",
    "        similarity_sum = sum(sim_scores[i][j] for i in in_neighbors_a for j in in_neighbors_b)\n",
    "        return (C / (len(in_neighbors_a) * len(in_neighbors_b))) * similarity_sum\n",
    "\n",
    "\n",
    "    def analyze_citation_graph(self, query_nodes, decay_factors, output_dir=\"simrank_results\"):\n",
    "        \"\"\"Run SimRank analysis on citation graph\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        assert os.path.isdir(output_dir), f\"Could not create or access directory: {output_dir}\"\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Get graph data from Neo4j\n",
    "        edges = self.get_graph_data()\n",
    "        edges_df = self.spark.createDataFrame(edges, [\"source\", \"target\"])\n",
    "        \n",
    "        # Cache in-neighbors\n",
    "        in_neighbors_dict = self._cache_in_neighbors(edges_df)\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        for C in decay_factors:\n",
    "            print(f\"\\nComputing SimRank with decay factor C = {C}\")\n",
    "            \n",
    "            results = []\n",
    "            # Get all unique nodes\n",
    "            all_nodes = set(row['source'] for row in edges_df.select(\"source\").distinct().collect())\n",
    "            all_nodes.update(row['target'] for row in edges_df.select(\"target\").distinct().collect())\n",
    "            \n",
    "            for query_node in tqdm(query_nodes, desc=\"Processing query nodes\"):\n",
    "                node_results = []\n",
    "                for target_node in tqdm(all_nodes, desc=f\"Computing similarities for node {query_node}\", leave=False):\n",
    "                    sim = self.compute_simrank_similarity(\n",
    "                        query_node,\n",
    "                        target_node,\n",
    "                        in_neighbors_dict,\n",
    "                        C\n",
    "                    )\n",
    "                    node_results.append((query_node, target_node, sim))\n",
    "                results.extend(node_results)\n",
    "            \n",
    "            results_df = pd.DataFrame(results, columns=['query_node', 'target_node', 'similarity'])\n",
    "            results_df['decay_factor'] = C\n",
    "            all_results.append(results_df)\n",
    "            \n",
    "            # Save intermediate results\n",
    "            output_path = f\"{output_dir}/simrank_results_C{C}_{timestamp}.csv\"\n",
    "            results_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        return self._save_and_summarize_results(all_results, query_nodes, decay_factors, timestamp, output_dir)\n",
    "\n",
    "    \n",
    "    def _cache_in_neighbors(self, edges_df):\n",
    "        \"\"\"Cache in-neighbors for all nodes\"\"\"\n",
    "        in_neighbors = edges_df.groupBy('target').agg(F.collect_list('source').alias('in_neighbors'))\n",
    "        return {row['target']: row['in_neighbors'] for row in in_neighbors.collect()}\n",
    "\n",
    "    \n",
    "    def _save_and_summarize_results(self, all_results, query_nodes, decay_factors, timestamp, output_dir):\n",
    "        \"\"\"Save and summarize final results\"\"\"\n",
    "        final_results = pd.concat(all_results, ignore_index=True)\n",
    "        \n",
    "        # Save complete results\n",
    "        final_path = f\"{output_dir}/simrank_all_results_{timestamp}.csv\"\n",
    "        final_results.to_csv(final_path, index=False)\n",
    "        \n",
    "        # Generate top results\n",
    "        top_results = []\n",
    "        for C in decay_factors:\n",
    "            for query in query_nodes:\n",
    "                mask = (final_results['decay_factor'] == C) & (final_results['query_node'] == query)\n",
    "                subset = final_results[mask].nlargest(10, 'similarity')\n",
    "                subset = subset.copy()\n",
    "                subset['rank'] = range(1, len(subset) + 1)\n",
    "                top_results.append(subset)\n",
    "        \n",
    "        top_results_df = pd.concat(top_results, ignore_index=True)\n",
    "        top_path = f\"{output_dir}/simrank_top_results_{timestamp}.csv\"\n",
    "        top_results_df.to_csv(top_path, index=False)\n",
    "        \n",
    "        self._print_summary(top_results_df, decay_factors, query_nodes)\n",
    "        \n",
    "        return final_results, top_results_df\n",
    "    \n",
    "    def _print_summary(self, top_results_df, decay_factors, query_nodes):\n",
    "        \"\"\"Print summary of results\"\"\"\n",
    "        print(\"\\nTop 5 most similar nodes for each query node and decay factor:\")\n",
    "        for C in decay_factors:\n",
    "            print(f\"\\nDecay factor C = {C}\")\n",
    "            for query in query_nodes:\n",
    "                print(f\"\\nQuery node: {query}\")\n",
    "                mask = (top_results_df['decay_factor'] == C) & (top_results_df['query_node'] == query)\n",
    "                top_5 = top_results_df[mask & (top_results_df['similarity'] > 0)].head(5)\n",
    "                \n",
    "                if not top_5.empty:\n",
    "                    print(top_5[['target_node', 'similarity', 'rank']].to_string(index=False))\n",
    "                else:\n",
    "                    print(\"No similar nodes found.\")\n",
    "            \n",
    "    def close(self):\n",
    "        \"\"\"Close the Neo4j and Spark sessions\"\"\"\n",
    "        self.driver.close()\n",
    "        self.spark.stop()\n",
    "\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = CitationGraphAnalyzer()\n",
    "\n",
    "try:\n",
    "    # Create Neo4j graph\n",
    "    print(\"Creating Neo4j graph...\")\n",
    "    analyzer.create_neo4j_graph(papers_data)\n",
    "    \n",
    "    # Run analysis\n",
    "    query_nodes = [2982615777, 1556418098]\n",
    "    decay_factors = [0.7, 0.8, 0.9]\n",
    "    \n",
    "    print(\"Running SimRank analysis...\")\n",
    "    final_results, top_results = analyzer.analyze_citation_graph(\n",
    "        query_nodes=query_nodes,\n",
    "        decay_factors=decay_factors\n",
    "    )\n",
    "    \n",
    "finally:\n",
    "    # Clean up connections\n",
    "    analyzer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "{code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `apoc.export.csv.query` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/1446206497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \"\"\"\n\u001b[1;32m     42\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Step 5: Initialize Spark Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, query, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mbookmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bookmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         self._auto_result._run(\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, query, parameters, db, imp_user, access_mode, bookmarks, notifications_min_severity, notifications_disabled_classifications)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/work/result.py\u001b[0m in \u001b[0;36m_attach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exhausted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNeo4jError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSessionExpired\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_bolt.py\u001b[0m in \u001b[0;36mfetch_message\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mhydration_hooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhydration_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         )\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midle_since\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_bolt5.py\u001b[0m in \u001b[0;36m_process_message\u001b[0;34m(self, tag, fields)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_server_state_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbolt_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_metadata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatabaseUnavailable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/neo4j/_sync/io/_common.py\u001b[0m in \u001b[0;36mon_failure\u001b[0;34m(self, metadata)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mhandler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hydrate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_ignored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `apoc.export.csv.query` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from itertools import product\n",
    "\n",
    "# Step 1: Load JSON Data\n",
    "# Open and read each line as a separate JSON object\n",
    "with open('train.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Step 2: Neo4j Database Connection\n",
    "uri = \"bolt://localhost:7687\"  # update if different\n",
    "username = \"neo4j\"  # replace with your Neo4j username\n",
    "password = \"paras2003\"  # replace with your Neo4j password\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Step 3: Create Graph in Neo4j\n",
    "def create_graph(tx, paper_id, references):\n",
    "    # Create a paper node\n",
    "    tx.run(\"MERGE (p:Paper {id: $paper_id})\", paper_id=paper_id)\n",
    "    # For each reference, create a citation edge\n",
    "    for ref_id in references:\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (p:Paper {id: $paper_id})\n",
    "            MERGE (r:Paper {id: $ref_id})\n",
    "            MERGE (p)-[:CITES]->(r)\n",
    "            \"\"\", paper_id=paper_id, ref_id=ref_id)\n",
    "\n",
    "# Add data to Neo4j\n",
    "# with driver.session() as session:\n",
    "#     for entry in data:\n",
    "#         paper_id = entry['paper']\n",
    "#         references = entry.get('reference', [])\n",
    "#         session.write_transaction(create_graph, paper_id, references)\n",
    "\n",
    "# Step 4: Export Neo4j Data to CSV\n",
    "export_query = \"\"\"\n",
    "CALL apoc.export.csv.query(\"MATCH (p1:Paper)-[:CITES]->(p2:Paper) RETURN p1.id AS paper, p2.id AS reference\", \"citation_graph.csv\", {})\n",
    "\"\"\"\n",
    "with driver.session() as session:\n",
    "    session.run(export_query)\n",
    "\n",
    "# Step 5: Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"SimRank\").getOrCreate()\n",
    "\n",
    "# Load citation graph CSV into a Spark DataFrame\n",
    "df = spark.read.csv(\"citation_graph.csv\", header=True, inferSchema=True)\n",
    "df.show()\n",
    "\n",
    "# Step 6: Define SimRank Algorithm\n",
    "def simrank(df, query_nodes, C=0.8, max_iter=10, tol=1e-4):\n",
    "    # Initialize similarity scores with 1.0 for self-similarity and 0.0 for all others\n",
    "    sim = {(u, v): 1.0 if u == v else 0.0 for u in query_nodes for v in query_nodes}\n",
    "    \n",
    "    # Dictionary to store incoming neighbors for each node\n",
    "    neighbors = df.rdd.map(lambda row: (row[\"reference\"], row[\"paper\"])) \\\n",
    "                      .groupByKey() \\\n",
    "                      .mapValues(list) \\\n",
    "                      .collectAsMap()\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        new_sim = {}\n",
    "        for u, v in product(query_nodes, repeat=2):\n",
    "            if u == v:\n",
    "                new_sim[(u, v)] = 1.0\n",
    "            else:\n",
    "                u_neighbors = neighbors.get(u, [])\n",
    "                v_neighbors = neighbors.get(v, [])\n",
    "                if u_neighbors and v_neighbors:\n",
    "                    scale = C / (len(u_neighbors) * len(v_neighbors))\n",
    "                    new_sim[(u, v)] = scale * sum(sim.get((w, x), 0) for w in u_neighbors for x in v_neighbors)\n",
    "                else:\n",
    "                    new_sim[(u, v)] = 0.0\n",
    "        \n",
    "        # Check for convergence\n",
    "        diff = sum(abs(new_sim[(u, v)] - sim[(u, v)]) for u, v in product(query_nodes, repeat=2))\n",
    "        if diff < tol:\n",
    "            break\n",
    "        sim = new_sim\n",
    "    \n",
    "    return sim\n",
    "\n",
    "# Step 7: Run SimRank Algorithm with Different Values of C\n",
    "results = {}\n",
    "for C_value in [0.7, 0.8, 0.9]:\n",
    "    results[C_value] = simrank(df, query_nodes=[2982615777, 1556418098], C=C_value)\n",
    "\n",
    "# Step 8: Display the Results\n",
    "for C_value, sim_scores in results.items():\n",
    "    print(f\"Results for C = {C_value}:\")\n",
    "    for (u, v), score in sim_scores.items():\n",
    "        print(f\"Similarity between {u} and {v}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/3786235644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m from .validation import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreadpoolctl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    604\u001b[0m from ._warnings_errors import (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    605\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 606\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_stats_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_variation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvariation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_measurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmilp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearConstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m from scipy._lib._util import (check_random_state, MapWrapper, _get_nan,\n\u001b[1;32m     44\u001b[0m                               \u001b[0mrng_integers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rename_parameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_contains_nan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_root_scalar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_minpack_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_zeros_py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_root_scalar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_zeros_py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptzeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_numdiff\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapprox_derivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_zeros_py.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_optimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizeResult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from itertools import product\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Step 1: Load JSON Data\n",
    "with open('train.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Step 2: Extract paper abstracts or content for topic modeling\n",
    "# Assuming that 'abstract' is a field in your data, adjust as needed\n",
    "documents = [entry['abstract'] for entry in data if 'abstract' in entry]\n",
    "\n",
    "# Step 3: Topic Modeling using LDA (Latent Dirichlet Allocation)\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Print out the topics discovered by LDA\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for index, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {index + 1}:\")\n",
    "    print([terms[i] for i in topic.argsort()[-10:]])  # top 10 words for each topic\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Step 4: Neo4j Database Connection\n",
    "uri = \"bolt://localhost:7687\"  # update if different\n",
    "username = \"neo4j\"  # replace with your Neo4j username\n",
    "password = \"paras2003\"  # replace with your Neo4j password\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Step 5: Create Graph in Neo4j\n",
    "def create_graph(tx, paper_id, references, topics):\n",
    "    # Create a paper node with topic information\n",
    "    tx.run(\"MERGE (p:Paper {id: $paper_id, topics: $topics})\", paper_id=paper_id, topics=topics)\n",
    "    # For each reference, create a citation edge\n",
    "    for ref_id in references:\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (p:Paper {id: $paper_id})\n",
    "            MERGE (r:Paper {id: $ref_id})\n",
    "            MERGE (p)-[:CITES]->(r)\n",
    "            \"\"\", paper_id=paper_id, ref_id=ref_id)\n",
    "\n",
    "# Step 6: Add data to Neo4j\n",
    "with driver.session() as session:\n",
    "    for i, entry in enumerate(data):\n",
    "        paper_id = entry['paper']\n",
    "        references = entry.get('reference', [])\n",
    "        # For each paper, assign the topic distribution from LDA\n",
    "        topic_distribution = lda.transform(vectorizer.transform([entry['abstract']])).flatten()\n",
    "        topics = list(topic_distribution)  # Storing topic distribution for the paper\n",
    "        session.write_transaction(create_graph, paper_id, references, topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/3805521953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 1: Load the data from the JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Step 2: Neo4j Database Connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/3805521953.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Step 1: Load the data from the JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Step 2: Neo4j Database Connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import GraphFrame\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Step 1: Load the data from the JSON file\n",
    "with open('train.json', 'r') as file:\n",
    "    data = [json.loads(line) for line in file]\n",
    "\n",
    "# Step 2: Neo4j Database Connection\n",
    "uri = \"bolt://localhost:7687\"  # Neo4j URI\n",
    "username = \"neo4j\"  # Replace with your username\n",
    "password = \"paras2003\"  # Replace with your password\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Step 3: Create Graph in Neo4j\n",
    "def create_graph(tx, paper_id, references):\n",
    "    # Create a paper node\n",
    "    tx.run(\"MERGE (p:Paper {id: $paper_id})\", paper_id=paper_id)\n",
    "    # Create a directed edge for each reference\n",
    "    for ref_id in references:\n",
    "        tx.run(\"\"\"\n",
    "            MERGE (p:Paper {id: $paper_id})\n",
    "            MERGE (r:Paper {id: $ref_id})\n",
    "            MERGE (p)-[:CITES]->(r)\n",
    "            \"\"\", paper_id=paper_id, ref_id=ref_id)\n",
    "\n",
    "# Add data to Neo4j with tqdm progress bar\n",
    "with driver.session() as session:\n",
    "    start_time = time.time()  # Track time for Neo4j insertion\n",
    "    for entry in tqdm(data, desc=\"Inserting into Neo4j\", unit=\"row\"):\n",
    "        paper_id = entry['paper']\n",
    "        references = entry.get('reference', [])\n",
    "        session.write_transaction(create_graph, paper_id, references)\n",
    "    print(f\"Neo4j insertion took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Step 4: Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SimRank\") \\\n",
    "    .config(\"spark.jars\", \"/Users/parasdhiman/Desktop/assmt/BDA/assmt3/graphframes-0.8.1-spark3.0-s_2.12.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 5: Load the graph data from Neo4j\n",
    "nodes_df = spark.read.format(\"neo4j\") \\\n",
    "    .option(\"url\", \"bolt://localhost:7687\") \\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\") \\\n",
    "    .option(\"authentication.basic.password\", \"paras2003\") \\\n",
    "    .option(\"query\", \"MATCH (p:Paper) RETURN p.id AS id\") \\\n",
    "    .load()\n",
    "\n",
    "edges_df = spark.read.format(\"neo4j\") \\\n",
    "    .option(\"url\", \"bolt://localhost:7687\") \\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\") \\\n",
    "    .option(\"authentication.basic.password\", \"paras2003\") \\\n",
    "    .option(\"query\", \"MATCH (p:Paper)-[:CITES]->(r:Paper) RETURN p.id AS src, r.id AS dst\") \\\n",
    "    .load()\n",
    "\n",
    "# Step 6: Create a GraphFrame\n",
    "g = GraphFrame(nodes_df, edges_df)\n",
    "\n",
    "# Step 7: SimRank Algorithm Implementation (simplified version)\n",
    "def simrank(g, C=0.7, max_iterations=1000, tolerance=0.0001):\n",
    "    # This function computes SimRank for all node pairs\n",
    "    sim_matrix = {}\n",
    "    nodes = g.vertices.select(\"id\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    # Initialize the similarity matrix\n",
    "    for u in nodes:\n",
    "        sim_matrix[u] = {}\n",
    "        for v in nodes:\n",
    "            sim_matrix[u][v] = 1.0 if u == v else 0.0\n",
    "\n",
    "    # Iterate to update similarities\n",
    "    for _ in tqdm(range(max_iterations), desc=\"SimRank Iterations\", unit=\"iteration\"):\n",
    "        prev_sim_matrix = {u: sim_matrix[u].copy() for u in sim_matrix}\n",
    "        for u in nodes:\n",
    "            for v in nodes:\n",
    "                if u != v:\n",
    "                    in_neighbors_u = [row['src'] for row in g.edges.filter(g.edges.dst == u).collect()]\n",
    "                    in_neighbors_v = [row['src'] for row in g.edges.filter(g.edges.dst == v).collect()]\n",
    "                    scale = C / (len(in_neighbors_u) * len(in_neighbors_v)) if in_neighbors_u and in_neighbors_v else 0\n",
    "                    sim_matrix[u][v] = scale * sum(sim_matrix.get(w, {}).get(x, 0) for w, x in product(in_neighbors_u, in_neighbors_v))\n",
    "\n",
    "        # Check for convergence\n",
    "        max_diff = max(abs(sim_matrix[u][v] - prev_sim_matrix[u][v]) for u in sim_matrix for v in sim_matrix[u])\n",
    "        if max_diff < tolerance:\n",
    "            break\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "# Step 8: Compute SimRank for different values of C and query nodes\n",
    "query_nodes = [2982615777, 1556418098]\n",
    "C_values = [0.7, 0.8, 0.9]\n",
    "\n",
    "for query in query_nodes:\n",
    "    for C in C_values:\n",
    "        print(f\"\\nRunning SimRank for query node {query} with C={C}...\")\n",
    "        start_time = time.time()\n",
    "        sim_matrix = simrank(g, C)\n",
    "        end_time = time.time()\n",
    "        print(f\"SimRank computation for C={C} took {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Print top-5 similar nodes (optional)\n",
    "        top_similar_nodes = sorted(sim_matrix[query].items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(f\"Top 5 similar nodes for query {query} (C={C}):\")\n",
    "        for node, similarity in top_similar_nodes:\n",
    "            print(f\"Node {node}: Similarity = {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 14:26:04 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "/Users/parasdhiman/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o11072.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:587)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wd/p8rd_3q56c3gyt1n_mf2kh8h0000gn/T/ipykernel_63214/252890955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Create GraphFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# Step 4: SimRank Algorithm in Spark (without NetworkX)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v, e)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m_java_api\u001b[0;34m(jsc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mjavaClassName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"org.graphframes.GraphFramePythonAPI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextClassLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaClassName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mnewInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o11072.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:445)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:587)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:520)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:568)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:833)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from neo4j import GraphDatabase\n",
    "from pyspark.sql import SparkSession\n",
    "from graphframes import GraphFrame\n",
    "from itertools import product\n",
    "\n",
    "# # Step 1: Load JSON Data into Neo4j\n",
    "# with open('train.json', 'r') as file:\n",
    "#     data = [json.loads(line) for line in file]\n",
    "\n",
    "# Neo4j connection parameters\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"paras2003\"\n",
    "\n",
    "# # Create Graph in Neo4j\n",
    "# def create_graph(tx, paper_id, references):\n",
    "#     # Create a paper node\n",
    "#     tx.run(\"MERGE (p:Paper {id: $paper_id})\", paper_id=paper_id)\n",
    "#     # For each reference, create a citation edge\n",
    "#     for ref_id in references:\n",
    "#         tx.run(\"\"\"\n",
    "#             MERGE (p:Paper {id: $paper_id})\n",
    "#             MERGE (r:Paper {id: $ref_id})\n",
    "#             MERGE (p)-[:CITES]->(r)\n",
    "#             \"\"\", paper_id=paper_id, ref_id=ref_id)\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# # Add data to Neo4j\n",
    "# with driver.session() as session:\n",
    "#     for entry in tqdm(data, desc=\"Loading data into Neo4j\", ncols=100):\n",
    "#         paper_id = entry['paper']\n",
    "#         references = entry.get('reference', [])\n",
    "        # session.write_transaction(create_graph, paper_id, references)\n",
    "\n",
    "# Step 2: Export graph from Neo4j to CSV\n",
    "def export_to_csv():\n",
    "    # Exporting Paper nodes to CSV\n",
    "    query = \"MATCH (p:Paper) RETURN p.id AS paper_id\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        papers = pd.DataFrame([record['paper_id'] for record in result], columns=['paper_id'])\n",
    "        papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "    # Exporting Citation edges to CSV\n",
    "    query = \"MATCH (p:Paper)-[:CITES]->(r:Paper) RETURN p.id AS citing_paper, r.id AS cited_paper\"\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        citations = pd.DataFrame([(record['citing_paper'], record['cited_paper']) for record in result], columns=['citing_paper', 'cited_paper'])\n",
    "        citations.to_csv('citations.csv', index=False)\n",
    "\n",
    "# Export data to CSV\n",
    "export_to_csv()\n",
    "\n",
    "# Step 3: Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Citation Graph Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load citation graph into Spark\n",
    "citations_df = spark.read.csv('citations.csv', header=True, inferSchema=True)\n",
    "papers_df = spark.read.csv('papers.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Convert to GraphFrame\n",
    "vertices = papers_df.selectExpr(\"paper_id as id\")\n",
    "edges = citations_df.selectExpr(\"citing_paper as src\", \"cited_paper as dst\")\n",
    "\n",
    "# Create GraphFrame\n",
    "g = GraphFrame(vertices, edges)\n",
    "\n",
    "# Step 4: SimRank Algorithm in Spark (without NetworkX)\n",
    "def simrank_algorithm(graph, source, target, C=0.8, max_iter=1000, tol=0.0001):\n",
    "    \"\"\"\n",
    "    Function to compute SimRank similarity between two nodes using Apache Spark\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store similarities for each node\n",
    "    sim_cache = {}\n",
    "    \n",
    "    def recursive_similarity(u, v):\n",
    "        if (u, v) in sim_cache:\n",
    "            return sim_cache[(u, v)]\n",
    "        \n",
    "        # Get in-neighbors for both nodes\n",
    "        in_neighbors_u = [row['src'] for row in graph.edges.filter(graph.edges.dst == u).collect()]\n",
    "        in_neighbors_v = [row['src'] for row in graph.edges.filter(graph.edges.dst == v).collect()]\n",
    "        \n",
    "        if not in_neighbors_u or not in_neighbors_v:\n",
    "            sim_cache[(u, v)] = 0\n",
    "            return 0\n",
    "        \n",
    "        # Calculate the similarity based on neighbors\n",
    "        scale = C / (len(in_neighbors_u) * len(in_neighbors_v)) if len(in_neighbors_u) > 0 and len(in_neighbors_v) > 0 else 0\n",
    "        similarity = scale * sum(recursive_similarity(w, x) for w, x in product(in_neighbors_u, in_neighbors_v))\n",
    "        \n",
    "        sim_cache[(u, v)] = similarity\n",
    "        return similarity\n",
    "    \n",
    "    return recursive_similarity(source, target)\n",
    "\n",
    "# Step 5: Run SimRank for query nodes with different C values\n",
    "def run_simrank():\n",
    "    # Query nodes\n",
    "    query_nodes = [2982615777, 1556418098]\n",
    "    \n",
    "    # Results for different C values\n",
    "    results = {}\n",
    "    for C in tqdm([0.7, 0.8, 0.9], desc=\"Running SimRank for different values of C\", ncols=100):\n",
    "        for query_node in query_nodes:\n",
    "            similar_nodes = {}\n",
    "            for row in g.vertices.collect():  # Loop through all vertices (papers)\n",
    "                node = row['id']\n",
    "                similarity = simrank_algorithm(g, query_node, node, C=C)\n",
    "                similar_nodes[node] = similarity\n",
    "            results[C] = similar_nodes\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run SimRank and get the results\n",
    "simrank_results = run_simrank()\n",
    "\n",
    "# Step 6: Output results\n",
    "for C, similar_nodes in simrank_results.items():\n",
    "    print(f\"SimRank results for C={C}:\")\n",
    "    sorted_similar_nodes = sorted(similar_nodes.items(), key=lambda x: x[1], reverse=True)\n",
    "    for node, sim in sorted_similar_nodes[:10]:  # Top 10 most similar nodes\n",
    "        print(f\"Node {node} -> Similarity: {sim}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
